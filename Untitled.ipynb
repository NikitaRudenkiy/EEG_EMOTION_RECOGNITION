{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pyeeg\n",
    "from bisect import bisect_left\n",
    "import sys\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import mne\n",
    "from copy import deepcopy\n",
    "\n",
    "MODULE_PATH = \"/path/to/__init__.py\"\n",
    "MODULE_NAME = \"entropy\"\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(MODULE_NAME, MODULE_PATH)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[spec.name] = module \n",
    "spec.loader.exec_module(module)\n",
    "\n",
    "from entropy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_der(x):\n",
    "    return np.mean(np.abs(x[1:]-x[0:-1]))\n",
    "\n",
    "def second_der(x):\n",
    "    return np.mean(np.abs(x[2:] - x[0:-2]))\n",
    "\n",
    "def first_der_norm(x):\n",
    "    return first_der(x/max(np.abs(x)))\n",
    "\n",
    "def second_der_norm(x):\n",
    "    return second_der(x/max(np.abs(x)))\n",
    "\n",
    "def samp_entropy(X):\n",
    "    return sample_entropy(X)\n",
    "\n",
    "def spec_entropy(X):\n",
    "    return spectral_entropy(X, 100)\n",
    "\n",
    "def sing_entropy(X):\n",
    "    return svd_entropy(X)\n",
    "\n",
    "def petrosyan(X):\n",
    "    return petrosian_fd(X)\n",
    "\n",
    "def Hig(X):  \n",
    "    return higuchi_fd(X)\n",
    "\n",
    "def Katz(X):\n",
    "    return katz_fd(X)\n",
    "\n",
    "functions = [np.mean, np.std, first_der, second_der, first_der_norm, second_der_norm,perm_entropy,app_entropy, samp_entropy,\n",
    "            spec_entropy, sing_entropy, petrosyan, Hig, Katz]\n",
    "\n",
    "\n",
    "def create_df(data, cut=2500, train=True, n_segments=10):\n",
    "    n = len(data['data'])\n",
    "    m = len(data['data'][0][0])\n",
    "    features_all = []\n",
    "    good_chanels = [2, 3, 4, 5, 8, 12, 14, 32, 30, 26, 22, 21, 20, 18]\n",
    "    for j in range(n_segments):\n",
    "        start = cut + j*(m - cut)//n_segments\n",
    "        finish = cut + (j + 1)*(m - cut)//n_segments\n",
    "        for i in range(n):\n",
    "            features = dict()\n",
    "            for ch in good_chanels:\n",
    "                for func in functions:\n",
    "                    features[f\"channel_{ch}_{func.__name__}\"] = func(data['data'][i][ch][start:finish])\n",
    "            if train:\n",
    "                features['arrousal'] = data['labels'][i][0]\n",
    "                features['valence'] = data['labels'][i][1]\n",
    "                features['dominance'] = data['labels'][i][2]\n",
    "                features['liking'] = data['labels'][i][3]\n",
    "        \n",
    "            features_all.append(features)\n",
    "    return pd.json_normalize(features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for fn in tqdm(os.listdir('data_preprocessed_python/')):\n",
    "    with open('data_preprocessed_python/'+fn, 'rb') as f:\n",
    "        data = pickle.loads(f.read(), encoding='latin1')\n",
    "        datasets.append(create_df(data))\n",
    "data_all = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data_all.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_all.drop(['arousal', 'valence', 'dominance', 'liking'], axis=1)\n",
    "y = data_all['arousal'].apply(lambda x: 0 if x <= 4 else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, cv\n",
    "\n",
    "\n",
    "cv_dataset = Pool(data=X,\n",
    "                  label=y)\n",
    "\n",
    "params = {\"iterations\": 10000,\n",
    "          \"depth\": 6,\n",
    "          \"loss_function\": \"Logloss\",\n",
    "          \"custom_metric\": \"Accuracy\",\n",
    "          \"verbose\": False}\n",
    "\n",
    "scores = cv(cv_dataset,\n",
    "            params,\n",
    "            fold_count=3,\n",
    "            plot=\"True\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_arousal_model = CatBoostClassifier(iterations=100, depth=2)\n",
    "#cat_arrosal_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(measure, data, model):\n",
    "    X = data_all.drop(['arousal', 'valence', 'dominance', 'liking'], axis=1)\n",
    "    y = data_all[measure].apply(lambda x: 0 if x <= 4 else 2 if x >= 6)\n",
    "    #mlp_model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='logistic')\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_model = train_model('arousal', data_all, cat_arrosal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_model = train_model('valence', data_all, cat_arrosal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominance_model = train_model('dominance', data_all, cat_arrosal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv_dataset = Pool(data=X,\n",
    "                  label=y)\n",
    "\n",
    "params = {\"iterations\": 100,\n",
    "          \"depth\": 2\n",
    "          \"loss_function\": \"Logloss\",\n",
    "          \"custom_metric\": \"Accuracy\",\n",
    "          \"verbose\": False}\n",
    "\n",
    "scores = cv(cv_dataset,\n",
    "            params,\n",
    "            fold_count=3,\n",
    "            plot=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotions(Aurosal, Valence, Dominance):\n",
    "    return Aurosal, Valence, Dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pickle.loads(open('data_preprocessed_python/s01.dat', 'rb').read(), encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data['labels'] = sample_data['labels']\n",
    "sample_data['data'] = sample_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_df(sample_data).drop(['arrousal', 'valence', 'dominance', 'liking'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrousal = arrousal_model.predict_proba(data)[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(sample_data['data'][0][0])\n",
    "for i in range(0, m, m//30):\n",
    "    sample = {'data':[]}\n",
    "    sample['data'].append(sample_data['data'][0][:,i:i+m//30])\n",
    "    df = create_df(sample, train=False, n_segments=1, cut=0)\n",
    "    print(f'Arrousal: {arrousal_model.predict_proba(df)[0][0]}')\n",
    "    print(f'Valence: {valence_model.predict_proba(df)[0][0]}')\n",
    "    print(f'Dominance: {dominance_model.predict_proba(df)[0][0]}')\n",
    "    print('--------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
