{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyeeg\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import mne\n",
    "import picard\n",
    "import time\n",
    "import sys\n",
    "import logging\n",
    "import statistics\n",
    "import pywt\n",
    "logging.getLogger(\"mne\").setLevel(logging.WARNING)\n",
    "#тут нужно указать путь в __init__.py из папки entropy\n",
    "\n",
    "MODULE_PATH = \"C:/Users/Никита/Desktop/entropy/__init__.py\"\n",
    "\n",
    "MODULE_NAME = \"entropy\"\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(MODULE_NAME, MODULE_PATH)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[spec.name] = module \n",
    "spec.loader.exec_module(module)\n",
    "\n",
    "from entropy import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функции для извлечения фичей из сырого ээг - сигнала\n",
    "\n",
    "def first_der(x):\n",
    "    return np.mean(np.abs(x[1:]-x[0:-1]))\n",
    "\n",
    "def second_der(x):\n",
    "    return np.mean(np.abs(x[2:] - x[0:-2]))\n",
    "\n",
    "def first_der_norm(x):\n",
    "    return first_der(x/max(np.abs(x)))\n",
    "\n",
    "def second_der_norm(x):\n",
    "    return second_der(x/max(np.abs(x)))\n",
    "def samp_entropy(X):\n",
    "    return sample_entropy(X)\n",
    "\n",
    "def spec_entropy(X):\n",
    "    return spectral_entropy(X, 100)\n",
    "\n",
    "def sing_entropy(X):\n",
    "    return svd_entropy(X)\n",
    "\n",
    "def petrosyan(X):\n",
    "    return petrosian_fd(X)\n",
    "\n",
    "def Hig(X):  \n",
    "    return higuchi_fd(X)\n",
    "\n",
    "def Katz(X):\n",
    "    return katz_fd(X)\n",
    "\n",
    "def power_4_8(X):\n",
    "    return pyeeg.bin_power(X, [4, 8], 1000)[0][0]\n",
    "\n",
    "def power_8_16(X):\n",
    "    return pyeeg.bin_power(X, [8, 16], 1000)[0][0]\n",
    "\n",
    "def power_16_32(X):\n",
    "    return pyeeg.bin_power(X, [16, 32], 1000)[0][0]\n",
    "\n",
    "def power_32_64(X):\n",
    "    return pyeeg.bin_power(X, [32, 64], 1000)[0][0]\n",
    "\n",
    "def freq_delta(X, Fs=100):\n",
    "    L = len(X)\n",
    "    data_fft = np.fft.fft(X)\n",
    "    frequency = abs(data_fft/L)\n",
    "    frequency = frequency[: L//2+1]*2\n",
    "    delta = frequency[L*1//Fs-1: L*4//Fs]\n",
    "    return np.std(delta)\n",
    "\n",
    "def freq_theta(X, Fs=100):\n",
    "    L = len(X)\n",
    "    data_fft = np.fft.fft(X)\n",
    "    frequency = abs(data_fft/L)\n",
    "    frequency = frequency[: L//2+1]*2\n",
    "    theta = frequency[L*4//Fs-1: L*8//Fs]\n",
    "    return np.std(theta)\n",
    "\n",
    "def freq_alpha(X, Fs=100):\n",
    "    L = len(X)\n",
    "    data_fft = np.fft.fft(X)\n",
    "    frequency = abs(data_fft/L)\n",
    "    frequency = frequency[: L//2+1]*2\n",
    "    alpha = frequency[L*5//Fs-1: L*13//Fs]\n",
    "    return np.std(alpha)\n",
    "\n",
    "def freq_beta(X, Fs=100):\n",
    "    L = len(X)\n",
    "    data_fft = np.fft.fft(X)\n",
    "    frequency = abs(data_fft/L)\n",
    "    frequency = frequency[: L//2+1]*2\n",
    "    beta = frequency[L*13//Fs-1: L*30//Fs]\n",
    "    return np.std(beta)\n",
    "\n",
    "def freq_gamma(X, Fs=100):\n",
    "    L = len(X)\n",
    "    data_fft = np.fft.fft(X)\n",
    "    frequency = abs(data_fft/L)\n",
    "    frequency = frequency[: L//2+1]*2\n",
    "    gamma = frequency[L*30//Fs-1: L*50//Fs]\n",
    "    return np.std(gamma)\n",
    "\n",
    "def wwlt(X):\n",
    "    coeffs = pywt.wavedec(X, 'db1', level=5)\n",
    "    cA2, cD2,cD3,cD4,cD5, cD6 = coeffs\n",
    "    gamma = cD5\n",
    "    beta = cD4\n",
    "    alpha = cD3\n",
    "    theta = cD2\n",
    "    return sum(gamma**2), sum(beta**2), sum(alpha**2), sum(theta**2)\n",
    "\n",
    "\n",
    "\n",
    "functions = [np.mean,\n",
    "             #np.std,\n",
    "             first_der,second_der,statistics.median,\n",
    "             #first_der_norm, second_der_norm,perm_entropy,app_entropy, samp_entropy,\n",
    "            #spec_entropy, sing_entropy, petrosyan, Hig, Katz, power_4_8, power_8_16, power_16_32, power_32_64,\n",
    "            #freq_delta, freq_theta, freq_alpha,\n",
    "             freq_beta, freq_gamma]\n",
    "def remove_eye_activity_ICA(data):\n",
    "    good_chanels = [2, 3, 4, 5, 8, 12, 14, 32, 30, 26, 22, 21, 20, 18]\n",
    "    ch_names = [\"AF3\", \"F3\", \"F7\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F8\", \"F4\",\"AF4\"]\n",
    "    EOG_chanels = [33, 34, 35, 36]\n",
    "    eeg = []\n",
    "    \n",
    "    for ch in good_chanels:\n",
    "        eeg.append(np.array(data[ch]))\n",
    "\n",
    "    for ch in EOG_chanels:\n",
    "        eeg.append(np.array(data[ch]))\n",
    "        \n",
    "    eeg = np.array(eeg) * 10e-6              #in volts\n",
    "    \n",
    "    info = mne.create_info(ch_names, 512, ch_types=[\"eeg\"] * 14 + [\"eog\"] * 4)\n",
    "    raw = mne.io.RawArray(eeg, info)\n",
    "    \n",
    "    raw_tmp = raw.copy()\n",
    "    raw_tmp.filter(1, None)\n",
    "    \n",
    "    ica = mne.preprocessing.ICA(method=\"picard\",\n",
    "                            fit_params={\"extended\": True},\n",
    "                            random_state=1)\n",
    "    ica.fit(raw_tmp)\n",
    "    #TODO: WHAT ICA'S ?\n",
    "    #ica.exclude = [1]\n",
    "    \n",
    "    raw_corrected = raw.copy()\n",
    "    \n",
    "    return raw_corrected.get_data()\n",
    "\n",
    "def remove_eye_activity_regr(data):\n",
    "    good_chanels = [2, 3, 4, 5, 8, 12, 14, 32, 30, 26, 22, 21, 20, 18]\n",
    "    EOG_chanels = [33, 34, 35, 36]\n",
    "    eeg = []\n",
    "    for ch in good_chanels:\n",
    "        eeg.append(np.array(data[ch]))\n",
    "\n",
    "    for ch in EOG_chanels:\n",
    "        eeg.append(np.array(data[ch]))\n",
    "    eeg = np.array(eeg) * 10e-6\n",
    "    eeg1 = eeg.copy()\n",
    "    info = mne.create_info(18, 512, ch_types=[\"eeg\"] * 14 + [\"eog\"] * 4)\n",
    "    raw1 = mne.io.RawArray(eeg, info)\n",
    "    raw2 = mne.io.RawArray(eeg1, info)\n",
    "    bip = np.array([[-1, 1, 0, 0], [0, 0, -1, 1]])\n",
    "    raw1_eog = bip @ raw1[14:, :][0]\n",
    "    raw2_eog = bip @ raw2[14:, :][0]\n",
    "    raw1_eeg = raw1[:14, :][0]\n",
    "    raw2_eeg = raw2[:14, :][0]\n",
    "    b = np.linalg.inv(raw1_eog @ raw1_eog.T) @ raw1_eog @ raw1_eeg.T\n",
    "    eeg_corrected = (raw2_eeg.T - raw2_eog.T @ b).T\n",
    "    raw3 = raw2.copy()\n",
    "    raw3._data[:14, :] = eeg_corrected\n",
    "    return np.array(raw3.to_data_frame().T[1:])\n",
    "\n",
    "def create_df(data, lables,subject, cut=2500, train=True, n_segments=10):\n",
    "    features_all = []\n",
    "    m = len(data[0])\n",
    "    #нужные каналы\n",
    "    \n",
    "    good_chanels = [2, 3, 4, 5, 8, 12, 14, 32, 30, 26, 22, 21, 20, 18]\n",
    "    ch_names = [\"AF3\", \"F3\", \"F7\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F8\", \"F4\",\"AF4\"]\n",
    "    #бьем нашу ээг на сегменты и бежим по ним в цикле \n",
    "    \n",
    "    for j in range(n_segments):\n",
    "        start = cut + j*(m - cut)//n_segments\n",
    "        finish = cut + (j + 1)*(m - cut)//n_segments\n",
    "        features = dict()\n",
    "        for k in range(14):\n",
    "            for func in functions:\n",
    "                features[f\"channel_{ch_names[k]}_{func.__name__}\"] = func(data[k][start:finish])\n",
    "        features['arousal'] = lables[0]\n",
    "        features['valence'] = lables[1]\n",
    "        features['dominance'] = lables[2]\n",
    "        features['liking'] = lables[3]\n",
    "        features['subject'] = subject\n",
    "        features_all.append(features)\n",
    "    return pd.json_normalize(features_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "# бежим по дериктории, применяем извлечение фичей ко всем файлам и склеиваем все фичи в один датасет\n",
    "\n",
    "for fn in tqdm(os.listdir('data_preprocessed_python/')):\n",
    "    with open('data_preprocessed_python/'+fn, 'rb') as f:\n",
    "        raw = pickle.loads(f.read(), encoding='latin1')\n",
    "        video = 0\n",
    "        while video < 40:\n",
    "            label = raw['labels'][video]\n",
    "            #print('Video:', video + 1,'file:', fn)\n",
    "            datasets.append(create_df(raw['data'][video], label, fn.split('.')[0]))\n",
    "            video += 1\n",
    "\n",
    "data_all = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wawelet_features = list(filter(lambda x: x.endswith('wwlt'), data_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for wfeature in wawelet_features:\n",
    "#    for i in range(4):\n",
    "#        data_all[wfeature + f\"_{i}\"] = data_all[wfeature].apply(lambda x: x[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_all.drop(wawelet_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#перемешиваем фичи, для улучшения обучения\n",
    "\n",
    "data_all = data_all.sample(frac=1)\n",
    "data_all\n",
    "#data_all.to_excel('features_and_lables.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем X и Y для обучения\n",
    "\n",
    "X = data_all.drop(['arousal', 'valence', 'dominance', 'liking', 'subject'], axis=1)\n",
    "y = data_all['arousal'].apply(lambda x: 0 if x <= 5.5 else 1)\n",
    "                              #if x > 4.5 and x < 5.5 else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сама модель\n",
    "\n",
    "from catboost import Pool, cv\n",
    "\n",
    "\n",
    "cv_dataset = Pool(data=X,\n",
    "                  label=y)\n",
    "\n",
    "params = {\"iterations\": 10000,\n",
    "          \"depth\": 6,\n",
    "          \"loss_function\": \"Logloss\",\n",
    "          \"custom_metric\": \"Accuracy\",\n",
    "          \"verbose\": False}\n",
    "\n",
    "scores = cv(cv_dataset,\n",
    "            params,\n",
    "            fold_count=3,\n",
    "            plot=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_arousal_model = CatBoostClassifier(iterations=10000, depth=6)\n",
    "cat_dominance_model = CatBoostClassifier(iterations=10000, depth=6)\n",
    "cat_valence_model = CatBoostClassifier(iterations=10000, depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(measure, data, model):\n",
    "    X = data_all.drop(['arousal', 'valence', 'dominance', 'liking', 'subject'], axis=1)\n",
    "    y = data_all[measure].apply(lambda x: 0 if x <= 4.5 else 1 if x > 4.5 and x < 5.5 else 2 )\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_model = train_model('arousal', data_all, cat_arousal_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = data_all.columns.values.tolist()\n",
    "for i in range(len(arousal_model.feature_importances_)):\n",
    "    print(headers[i],' :', arousal_model.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "pkl.dump(arousal_model, open(\"arousal_removed_eyes.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominance_model = train_model('dominance', data_all, cat_dominance_model)\n",
    "pkl.dump(dominance_model, open(\"dominance_removed_eyes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_model = train_model('valence', data_all, cat_valence_model)\n",
    "pkl.dump(valence_model, open(\"valence_removed_eyes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arousal.pkl', 'rb') as f:\n",
    "    model_arousal = pkl.load(f)\n",
    "with open('dominance.pkl', 'rb') as f:\n",
    "    model_dominance = pkl.load(f)\n",
    "with open('valence.pkl', 'rb') as f:\n",
    "    model_valence = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data_preprocessed_python/s01.dat', 'rb')\n",
    "data = pickle.loads(f.read(), encoding='latin1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
